









NA ÚLTIMA AULA,

VIMOS QUE PODEMOS FACILMENTE 
SETTAR NOSSA PIPE,

TAMBÉM COM O SETUP DE NOTIFICATIONS 
SQS NO BUCKET S3 DA AWS...









-> NA PARTE DE NOSSO CÓDIGO,


RODAMOS ISTO:






-- CREATE TABLE FIRST 
CREATE OR REPLACE TABLE OUR_FIRST_DB.PUBLIC.employees (
        ID INT,
        first_name STRING,
        last_name STRING,
        email STRING,
        location STRING,
        department STRING
    );
-- Create File format Object 
CREATE OR REPLACE FILE FORMAT MANAGE_DB.file_formats.csv_file_format_new TYPE = CSV field_delimiter = ',',
    skip_header = 1 null_if =('NULL', 'null') empty_field_as_null = TRUE;




-- CREATE STAGE
CREATE OR REPLACE STAGE MANAGE_DB.stages.csv_folder
    URL = 's3://snowflake-test-masterclass-bucket/CSV/snowpipe'
    STORAGE_INTEGRATION= S3_EXAMPLE_INTEGRATION
    FILE_FORMAT=(
        FORMAT_NAME=MANAGE_DB.FILE_FORMATS.CSV_FILE_FORMAT
    );



-- LIST FILES IN BUCKET FOLDER/stage 

LIST @MANAGE_DB.stages.csv_folder;



-- CREATE SCHEMA TO STORE SNOWPIPE PIPES 

CREATE OR REPLACE SCHEMA MANAGE_DB.pipes;




-- Create ACTUAL PIPE OBJECT 

CREATE OR REPLACE PIPE MANAGE_DB.pipes.employee_pipe
    AUTO_INGEST = TRUE -- sempre deve ser definido como TRUE
   -- podemos executar apenas esta parte, do copy into, para verificar se coisas estao funcionando (para que o pipe nao execute 1 copy que nao funciona)
    AS 
    COPY INTO OUR_FIRST_DB.PUBLIC.employees
    FROM @MANAGE_DB.stages.csv_folder;





-- VC SEMPRE DEVE TESTAR O COMANDO DE COPY,

-- ANTES DE EMBUTI-LO NO PIPE.





-- --> COM ISSO, A PIPE ESTARÁ SETTADA...
-- ENTRETANTO, ELA AINDA __ NAO FUNCIONARÁ.
-- PARA QUE FUNCIONE, PRECISAMOS SETTAR 
-- S3 NOTIFICATIONS... TAMBÉM PRECISAMOS 
-- SETTAR PERMISSIONS PARA QUE O SNOWFLAKE 
-- CONSIGA __RECEBER ESSAS NOTIFICATIONS...

-- SÓ ENTAO ELE CONSEGUIRÁ COMECAR O COPYING,
-- A PARTIR DO INSERT DE ARQUIVOS NO BUCKET.






-- CHECKS FOR EXISTENCE OF PIPE.
DESC PIPE MANAGE_DB.pipes.employee_pipe;



















---------------------











OK, ATÉ AÍ TUDO BEM,


MAS ISSO 



ASSUME QUE TUDO DEU CERTO COM 


NOSSA PIPE...










--> MAS E SE ACONTECER ALGO DE ERRADO 



COM O COMANDO DE COPY? O QUE FAZEMOS, ENTAO?











-> VEREMOS COMO PODEMOS HANDLAR ERRORS,


E QUE COISAS PODEMOS FAZER...















O PROFESSOR ESCREVE ESTE CÓDIGO, PARA FORCAR 1 ERRO:






-- Handling Errors 


-- Create file format object (with wrong file format - field delimiter is wrong, in the file its ",", and not ';' )


CREATE OR REPLACE FILE FORMAT MANAGE_DB.file_formats.CSV_FILE_FORMAT
    type = csv
    field_delimiter=';'
    skip_header=1
    null_if=('NULL', 'null')
    empty_field_as_null = TRUE;







---------------------------------









ERROS CERTAMENTE OCORRERAO, POR CONTA 
DESSE FILE FORMAT.









AÍ TENTAMOS RODAR O MESMO 


COMANDO DE 

COPY DO PIPE,
TIPO ASSIM:




TRUNCATE TABLE OUR_FIRST_DB.public.employees;

-- testing error, with simple copy command -- error (number of columns doesnt match)
COPY INTO OUR_FIRST_DB.PUBLIC.employees
FROM @MANAGE_DB.stages.csv_folder;






















ok... isso deu erro, sim...










NAO VAI FUNCIONAR, PQ AS COMMAS 

NAO FORAM 

INTERPRETADAS COMO COLUMN DELIMITERS..






--> E NOSSA TABLE TEM 6 COLUMNS,


NAO APENAS 1...










--> MAS O QUE ACONTECE 


SE _ ESSA PIPE 


TENTA __ CARREGAR A DATA...








-> TENTA CARREGAR A DATA QUE ESTÁ __eRRADA_ 

(file format errado, dentro do copy command)....













-> OK.... AGORA DEVEMOS UPLOADAR 1 NOVO

FILE,


1 FILE COMUM, MAS COM ","


SEPARANDO --> VAI CAUSAR 1 ERRO....













UPLOADAMOS 1 NOVO ARQUIVO CSV NA PASTA 

SNOWPIPE DOS NOSSOS BUCKETS...







enviamos employee_Data_3.csv...








ISSO VAI TRIGGAR O EVENT...














-------> ADICIONAMOS ISSO NO AWS S3 BUCKET.










certo... depois disso, o que fazemos....










--> PARA ___CHECARMOS __ O QUE 

ACONTECEU 

COM NOSSO SNOWPIPE,


TEMOS 1 COMANDO ESPECIAL,

QUE É 




ALTER PIPE employee_pipe REFRESH;












-> MAS ISSO MOSTRA QUE NOSSA FILE FOI 

""SENT"" --> quer dizer que 

o snowflake/snowpipe 

JÁ FOI NOTIFICADO, a esse momento.
















--> mas a primeira coisa que 




DEVEMOS FAZER,

SE ALGUMAS ROWS 

NAO APARECEREM 


NA NOSSA TABLE,

MESMO 


COM NOSSO 


PIPE ESTANDO SETTADO,





É 

RODAR 


ESTE COMANDO:








--> mas a primeira coisa que 
-- DEVEMOS FAZER,
-- SE ALGUMAS ROWS 
-- NAO APARECEREM 
-- NA NOSSA TABLE,
-- MESMO 
-- COM NOSSO
-- PIPE ESTANDO SETTADO,
-- É 
-- RODAR
-- ESTE COMANDO:


-- Validate pipe - checks if pipe is actually working 
SELECT SYSTEM$PIPE_STATUS('employee_pipe');







---------------------------










CERTO....



SELECT SYSTEM$PIPE_STATUS('employee_pipe');









e o que isso nos mostrou?







isto:







{"executionState":"RUNNING",
"pendingFileCount":0,
"lastIngestedTimestamp":"2023-07-20T15:00:11.051Z",
"lastIngestedFilePath":"/employee_data_2.csv",
"notificationChannelName":"arn:aws:sqs:us-east-1:475055360349:sf-snowpipe-AIDAW5G4BRFO5Q3ZE3DWI-0N6R2utYyOFCy5TOernvnw",
"numOutstandingMessagesOnChannel":1,
"lastReceivedMessageTimestamp":"2023-07-20T14:57:58.74Z",
"lastForwardedMessageTimestamp":"2023-07-20T14:57:59.171Z",
"lastPulledFromChannelTimestamp":"2023-07-20T15:04:38.728Z",
"lastForwardedFilePath":"snowflake-test-masterclass-bucket/CSV/snowpipe/employee_data_3.csv"}
















COMO TEMOS "RUNNING",

SIGNIFICA QUE ESSE PIPE AINDA ESTÁ RODANDO...


pendingFileCount 0 SIGNIFCA QUE TODAS 

AS FILES JA FORAM PROCESSADAS...










-> SE QUISERMOS RECEBER 1 ERROR 
MESSAGE DESSA PIPE,

PRECISAMOS USAR 1 SELECT COMMAND 

TOTALMENTE DIFERENTE....






O COMANDO É ESTE:




-- Snowpipe error message 
 SELECT * fROM TABLE(VALIDATE_PIPE_LOAD(
    PIPE_NAME => 'MANAGE_DB.pipes.employee_pipe',
    START_TIME => DATEADD(HOUR, -2, CURRENT_TIMESTAMP())
 ));






 EM UMA DAS COLUMNS,
 TEMOS:







 Remote file 'https://snowflake-test-
 masterclass-bucket.s3.us-east-1.amazonaws.
 com/CSV/snowpipe//employee_data_3.csv' 
 was not found. There are several 
 potential causes. The file might not exist.
  The required credentials may be
   missing or invalid. If you are
    running a copy command, please make 
    sure files are not deleted when they
     are being loaded or files are not being
      loaded into two different tables
       concurrently with auto purge option.











ESSA ERROR MESSAGE É BEM ESTRANHA...










FALA DE REMOTE FILE.... REMOTE FILE NAO FOI ENCONTRADA...






VÁRIAS CAUSAS EM POTENCIAL, ETC...







--> É UMA STANDARD MESSAGE,


QUE É 

A MESSAGE MAIS COMUM QUE RECEBEMOS, SE ALGO 


DÁ ERRADO NO NOSSO SNOWPIPE...








QUER DIZER QUE ESSA MESSAGE NAO NOS AJUDA COM QUASE 

NADA....










NA VERDADE, O COMANDO MAIS ÚTIL QUE PODEMOS 

UTILIZAR 

É 


O 

DE 


""COPY HISTORY"",




COPIAR A HISTORY DA TABLE EM QUE QUERÍAMOS COPIAR 

A DATA DO S3 BUCKET...


TIPO ASSIM:









-- COPY history from table to see error message (better error messages):

SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(
    table_name => 'OUR_FIRST_DB.PUBLIC.employees',
    START_TIME => DATEADD(HOUR, -2, CURRENT_TIMESTAMP())
))









E ISSO REALMENTE NOS DÁ INFORMACAO UTIL....





TEMOS 1 COLUMN DE 


""first_error_message"",

que é realmente útil...



ganhamos este error:



Number of columns in file (1) 
does not match that of the corresponding table 
(6), use file format 
option error_on_column_count_mismatch=false
 to ignore this error













E ISSO REALMENTE NOS DÁ INFORMACAO UTIL....





TEMOS 1 COLUMN DE 


""first_error_message"",

que é realmente útil...



ganhamos este error:



Number of columns in file (1) 
does not match that of the corresponding table 
(6), use file format 
option error_on_column_count_mismatch=false
 to ignore this error


 --------------------------














 ESPECIFICAMOS A TABLE NAME,


 E O START TIME... --> ISSO 



 NOS DÁ TODA A COPY_HISTORY 

 DESSA TABLE...










 COPY_HISTORY NA VERDADE É UM SCHEMA SUPER ÚTIL,

 COMO JÁ CONSTATAMOS....














PODEMOS ENVIAR OUTRA FILE,


O employee_data_4,



também com delimiter errado,


para que 

consigamos 



checar essa copy history,

e 
outro erro, novamente...









QUER DIZER QUE DEVEMOS USAR 

ESSE COMANDO,

PARA DESCOBRIR MAIS SOBRE ERRORS 

DURANTE O RUN DO SNOWPIPE...



-- COPY history from table to see error message (better error messages):

SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(
    table_name => 'OUR_FIRST_DB.PUBLIC.employees',
    START_TIME => DATEADD(HOUR, -2, CURRENT_TIMESTAMP())
));


